{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "\n",
    "As you might know, working with any kind of machine learning model requires at least 80% of data munging (that is, preparing, cleaning and transforming the data to make it suitable for modeling) and no more than 20% of the time is spent with actual modeling.\n",
    "\n",
    "This time we would like to train a binary classifier for sarcasm detection. We have a set of news headlines that are either serious or sarcastic ones. \n",
    "\n",
    "1. Download the [dataset](https://raw.githubusercontent.com/rishabhmisra/News-Headlines-Dataset-For-Sarcasm-Detection/master/Sarcasm_Headlines_Dataset.json).\n",
    "2. Read the data: in each line `headline` contains the text, `is_sarcastic` is the label.\n",
    "3. Split the data into training and test set.\n",
    "4. Represent each headline with a vector (apply a vector space model for text data, using individual words as tokens/terms). Do some cleaning if necessary (stop-word removal, stemming, quotation mark removal, special character removal, etc.). Check the scikit-learn classes in the [feature extraction for text](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_extraction.text) module that might be useful for this task, particularly CountVectorizer, TfidfTransformer, TfidfVectorizer.\n",
    "5. Build a [logistic regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression) using $l_2$-regularization on the training set. You might want to choose the best regularization parameter, so you can split the training set to two parts: one for training, the other one for validation and pick the regularization parameter that provides the best result on the validation set. Check [logistic regression with cross-validation](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html#sklearn.linear_model.LogisticRegressionCV). Read how these methods are used. You do not have to implement any of these from scratch. Learn how to use already implemented models in scikit-learn.\n",
    "6. Evaluate the model on the test data.\n",
    "7. Obtaining 0.75 accuracy on the test set should not be hard, set your goal for creating an even better model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/rishabhmisra/News-Headlines-Dataset-For-Sarcasm-Detection/master/Sarcasm_Headlines_Dataset.json \\\n",
    "    -O /tmp/sarcasm.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "# add more imports if needed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
