{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Feature engineering - nonlinear decision boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.metrics as mcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"./data/log_reg_3.txt\") as f:\n",
    "    X = []\n",
    "    y = []\n",
    "    for line in f:\n",
    "        x0, x1, label = line.split(',')\n",
    "        X.append((float(x0), float(x1)))\n",
    "        y.append(int(float(label)))\n",
    "\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.expand_dims(np.array(y), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def initialize_params(X):\n",
    "    _, nr_features = X.shape\n",
    "    w0 = np.zeros((nr_features, 1), dtype=np.float_)\n",
    "    b = 0.0\n",
    "    return w0, b\n",
    "\n",
    "\n",
    "def activation(Z):\n",
    "    return 1 / (1 + np.exp(-Z))\n",
    "\n",
    "\n",
    "def predict(X, w, b):\n",
    "    A = activation(np.matmul(X, w) + b)\n",
    "    return np.round(A)\n",
    "\n",
    "\n",
    "def calc_gradient(X, y, w, b):\n",
    "    m = len(X)\n",
    "    A = activation(np.matmul(X, w) + b)\n",
    "    cost = (-1 / m) * np.sum(np.multiply(y, np.log(A)) + np.multiply(1 - y, np.log(1 - A)))\n",
    "    \n",
    "    dZ = A - y\n",
    "    dw = (1 / m) * np.matmul(X.T, dZ)\n",
    "    db = (1 / m) * np.sum(dZ)\n",
    "    return cost, dw, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def batch_gd(X, y, alpha, nr_epochs=1000):\n",
    "    w, b = initialize_params(X)\n",
    "    costs = []\n",
    "    for _ in range(nr_epochs):\n",
    "        cost, dw, db = calc_gradient(X, y, w, b)\n",
    "        costs.append(cost)\n",
    "        w = w - alpha * dw\n",
    "        b = b - alpha * db\n",
    "    return costs, w, b\n",
    "\n",
    "\n",
    "alpha = 0.01\n",
    "costs, w, b = batch_gd(X, y, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(16, 8))\n",
    "plt.plot(costs)\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "predictions = predict(X, w, b)\n",
    "\n",
    "\n",
    "def accuracy(predicted, ground_truth):\n",
    "    return np.sum(predicted == ground_truth) / len(ground_truth)\n",
    "\n",
    "\n",
    "print(accuracy(predictions, y))\n",
    "mcs.confusion_matrix(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def expand(X):\n",
    "    M = np.copy(X)\n",
    "    Q = np.array([np.square(X[:, 0]), np.multiply(X[:, 0], X[:, 1]), np.square(X[:, 1])]).T\n",
    "    return np.hstack((M, Q))\n",
    "\n",
    "\n",
    "def expand_3(X):\n",
    "    M = expand(X)\n",
    "    Q = np.array(\n",
    "        [np.power(X[:, 0], 3), \n",
    "         np.multiply(np.power(X[:, 0], 2), X[:, 1]), \n",
    "         np.multiply(X[:, 0], np.power(X[:, 1], 2)),\n",
    "         np.power(X[:, 1], 3)]).T\n",
    "    return np.hstack((M, Q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "M = expand(X)\n",
    "\n",
    "\n",
    "m = np.mean(M, axis=0)\n",
    "s = np.std(M, axis=0, ddof=1)\n",
    "M = (M - m) / s\n",
    "\n",
    "\n",
    "alpha = 0.01\n",
    "costs, w, b = batch_gd(M, y, alpha, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(16, 8))\n",
    "plt.plot(costs)\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "predictions = predict(M, w, b)\n",
    "\n",
    "\n",
    "def accuracy(predicted, ground_truth):\n",
    "    return np.sum(predicted == ground_truth) / len(ground_truth)\n",
    "\n",
    "\n",
    "print(accuracy(predictions, y))\n",
    "mcs.confusion_matrix(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "h = 0.01\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "meshpoints = np.c_[xx.ravel(), yy.ravel()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "Z = (expand(meshpoints) - m) / s\n",
    "Z = predict(Z, w, b)\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.contourf(xx, yy, Z, alpha=0.1)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "M = expand_3(X)\n",
    "\n",
    "\n",
    "m = np.mean(M, axis=0)\n",
    "s = np.std(M, axis=0, ddof=1)\n",
    "M = (M - m) / s\n",
    "\n",
    "\n",
    "alpha = 0.01\n",
    "costs, w, b = batch_gd(M, y, alpha, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(16, 8))\n",
    "plt.plot(costs)\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "predictions = predict(M, w, b)\n",
    "\n",
    "\n",
    "def accuracy(predicted, ground_truth):\n",
    "    return np.sum(predicted == ground_truth) / len(ground_truth)\n",
    "\n",
    "\n",
    "print(accuracy(predictions, y))\n",
    "mcs.confusion_matrix(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "h = 0.01\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "meshpoints = np.c_[xx.ravel(), yy.ravel()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "Z = (expand_3(meshpoints) - m) / s\n",
    "Z = predict(Z, w, b)\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.contourf(xx, yy, Z, alpha=0.1)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Batch gradient descent and other optimization methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"./data/log_reg_1.txt\") as f:\n",
    "    X = []\n",
    "    y = []\n",
    "    for line in f:\n",
    "        x0, x1, label = line.split(',')\n",
    "        X.append((float(x0), float(x1)))\n",
    "        y.append(int(label))\n",
    "        \n",
    "X = np.array(X)\n",
    "y = np.expand_dims(np.array(y), 1)\n",
    "\n",
    "X = (X - np.mean(X, axis=0)) / np.std(X, axis=0, ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def generate_batches(X, y, batch_size):\n",
    "    length = len(y)\n",
    "    indices = np.arange(length)\n",
    "    np.random.shuffle(indices)\n",
    "    ix = 0\n",
    "    while ix < length:\n",
    "        mini_batch_indices = indices[ix:ix+batch_size]\n",
    "        yield X[mini_batch_indices, :], y[mini_batch_indices]\n",
    "        ix += batch_size\n",
    "    \n",
    "\n",
    "\n",
    "def minibatch_gd(X, y, alpha, batch_size, nr_epochs=1000):\n",
    "    w, b = initialize_params(X)\n",
    "    costs = []\n",
    "    for _ in range(nr_epochs):\n",
    "        batch_generator = generate_batches(X, y, batch_size)\n",
    "        for X_batch, y_batch in batch_generator:\n",
    "            cost, dw, db = calc_gradient(X_batch, y_batch, w, b)\n",
    "            costs.append(cost)\n",
    "            w = w - alpha * dw\n",
    "            b = b - alpha * db\n",
    "    return costs, w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "alpha = 0.01\n",
    "costs, w, b = minibatch_gd(X, y, alpha, 20, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(16, 8))\n",
    "plt.plot(costs)\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gradient descent with momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Momentum is a method that helps accelerate SGD in the relevant direction and dampens oscillations.\n",
    "\n",
    "$$\n",
    "v_{dw} = \\beta v_{dw} + (1 - \\beta) \\cdot dw\n",
    "$$\n",
    "\n",
    "$$\n",
    "v_{db} = \\beta v_{db} + (1 - \\beta) \\cdot db\n",
    "$$\n",
    "\n",
    "\n",
    "The update step smoothes out the heavy oscillations\n",
    "\n",
    "$$\n",
    "w = w - \\alpha \\cdot v_{dw}\n",
    "$$\n",
    "\n",
    "$$\n",
    "b = b - \\alpha\\cdot v_{db}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def minibatch_gd_momentum(X, y, alpha, beta, batch_size, nr_epochs=1000):\n",
    "    w, b = initialize_params(X)\n",
    "    v_dw, v_db = initialize_params(X)\n",
    "    costs = []\n",
    "    for _ in range(nr_epochs):\n",
    "        batch_generator = generate_batches(X, y, batch_size)\n",
    "        for X_batch, y_batch in batch_generator:\n",
    "            cost, dw, db = calc_gradient(X_batch, y_batch, w, b)\n",
    "            costs.append(cost)\n",
    "            v_dw = beta * v_dw + (1 - beta) * dw\n",
    "            v_db = beta * v_db + (1 - beta) * db\n",
    "            \n",
    "            w = w - alpha * v_dw\n",
    "            b = b - alpha * v_db\n",
    "    return costs, w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "alpha = 0.001\n",
    "beta = 0.9\n",
    "costs, w, b = minibatch_gd_momentum(X, y, alpha, beta, 20, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(16, 8))\n",
    "plt.plot(costs)\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The learning algorithm can be speed-up in various other ways\n",
    "\n",
    "\n",
    "### RMSprop \n",
    "\n",
    "This is unpublished optimization algorithm designed for neural networks, proposed by Geoff Hinton in lecture 6 of the online course \"Neural Networks for Machine Learning\".\n",
    "\n",
    "\n",
    "Root mean square prop or RMSprop is using the same concept of the exponentially weighted average of the gradients like gradient descent with momentum but the difference is the update of parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](images/hinton_rmsprop.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### RMSProp\n",
    "\n",
    "$$\n",
    "s_{dw} = \\beta\\cdot s_{dw} + (1 - \\beta)\\cdot dw^2 \\qquad \\text{(elementwise square)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "s_{dv} = \\beta\\cdot s_{dv} + (1 - \\beta)\\cdot dv^2\\qquad \\text{(elementwise square)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "w = w - \\alpha \\frac{dw}{\\sqrt{\\epsilon + s_{dw}}}\n",
    "$$\n",
    " \n",
    "$$\n",
    "b = b - \\alpha \\frac{db}{\\sqrt{\\epsilon + s_{db}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def minibatch_gd_rmsprop(X, y, alpha, beta, batch_size, nr_epochs=1000):\n",
    "    w, b = initialize_params(X)\n",
    "    costs = []\n",
    "    eps = 1e-8\n",
    "    for _ in range(nr_epochs):\n",
    "        batch_generator = generate_batches(X, y, batch_size)\n",
    "        for X_batch, y_batch in batch_generator:\n",
    "            cost, dw, db = calc_gradient(X_batch, y_batch, w, b)\n",
    "            costs.append(cost)\n",
    "            ###TODO:\n",
    "            # ???\n",
    "            # ???\n",
    "            \n",
    "            # w = w - alpha * ???\n",
    "            # b = b - alpha * ???\n",
    "            ###\n",
    "    return costs, w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Adaptive moment estimation (ADAM)\n",
    "\n",
    "On iteration $k$:\n",
    "$$\n",
    "v_{dw} = \\beta_1\\cdot v_{dw} + (1 - \\beta_1)\\cdot dw,\\qquad v_{db} = \\beta_1\\cdot v_{db} + (1 - \\beta_1)\\cdot db\n",
    "$$\n",
    "\n",
    "$$\n",
    "s_{dw} = \\beta_2\\cdot s_{dw} + (1 - \\beta_2)\\cdot dw^2,\\qquad s_{db} = \\beta_2\\cdot s_{db} + (1 - \\beta_2)\\cdot db^2,\n",
    "$$\n",
    "\n",
    "$$\n",
    "v_{dw}^c = \\frac{v_{dw}}{1 - \\beta_1^k},\\qquad v_{db}^c = \\frac{v_{db}}{1 - \\beta_1^k},\\qquad s_{dw}^c = \\frac{s_{dw}}{1 - \\beta_2^k},\\qquad s_{db}^c = \\frac{s_{db}}{1 - \\beta_2^k}\n",
    "$$\n",
    "Finally,\n",
    "\n",
    "$$\n",
    "w = w - \\alpha\\cdot \\frac{v_{dw}^c}{\\sqrt{s_{dw}^c + \\epsilon}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "b = b - \\alpha\\cdot \\frac{v_{db}^c}{\\sqrt{s_{db}^c + \\epsilon}}\n",
    "$$\n",
    "\n",
    "$\\beta_1\\approx 0.9$, $\\beta_2\\approx 0.99$, $\\epsilon\\approx 10^{-10}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def minibatch_gd_adam(X, y, alpha, beta1, beta2, batch_size, nr_epochs=1000):\n",
    "    w, b = initialize_params(X)\n",
    "    eps = 1e-10\n",
    "    costs = []\n",
    "    for k in range(nr_epochs):\n",
    "        batch_generator = generate_batches(X, y, batch_size)\n",
    "        for X_batch, y_batch in batch_generator:\n",
    "            cost, dw, db = calc_gradient(X_batch, y_batch, w, b)\n",
    "            costs.append(cost)\n",
    "            ###TODO:\n",
    "            # ???\n",
    "            # ???\n",
    "            \n",
    "            # w = w - alpha * ???\n",
    "            # b = b - alpha * ???\n",
    "            ###\n",
    "    return costs, w, b"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
