{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import zipfile\n",
    "\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "!wget http://mlg.ucd.ie/files/datasets/bbc-fulltext.zip -O /tmp/bbc-fulltext.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "zip_ref = zipfile.ZipFile('/tmp/bbc-fulltext.zip', 'r')\n",
    "zip_ref.extractall('/tmp/')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "base_dir = '/tmp/bbc/'\n",
    "\n",
    "\n",
    "def get_subfolders(path):\n",
    "    return [f.path for f in os.scandir(path) if f.is_dir()]\n",
    "\n",
    "\n",
    "def get_filenames(path):\n",
    "    return [f.path for f in os.scandir(path) if f.is_file()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "labels = get_subfolders(base_dir)\n",
    "\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    return re.sub(\"\\s+\", \" \", text).strip()\n",
    "\n",
    "\n",
    "def read_document(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"ISO-8859-1\") as article:\n",
    "        text = article.read().replace(\"\\n\", \" \")\n",
    "    cleaned_text = clean_text(text)\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "def iterate_over_documents(path):\n",
    "    subfolders = get_subfolders(path)\n",
    "    for subfolder in subfolders:\n",
    "        label = subfolder.split('/')[-1]\n",
    "        file_paths = get_filenames(subfolder)\n",
    "        for file_path in file_paths:\n",
    "            file_name = file_path.split('/')[-1]\n",
    "            content = read_document(file_path)\n",
    "            yield label, file_name, content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def process_article(text, stop_words):\n",
    "    content = defaultdict(int)\n",
    "    stemmer = PorterStemmer()\n",
    "    for word in text.split():\n",
    "        lowercase = word.lower()\n",
    "        # non-letter characters at the beginning/end of the word are replaced\n",
    "        lowercase = re.sub(\"^[^a-z]*|[^a-z]*$\", \"\", lowercase)\n",
    "        if lowercase and lowercase not in stop_words:\n",
    "            word = stemmer.stem(word)\n",
    "            content[word] += 1\n",
    "    return dict(content)\n",
    "\n",
    "\n",
    "def create_document_word_counts(path):\n",
    "    documents = []\n",
    "    document_generator = iterate_over_documents(path)\n",
    "    stop_words = stopwords.words(\"english\")\n",
    "    for label, file_name, text in document_generator:\n",
    "        word_counts = process_article(text, stop_words)\n",
    "        documents.append((label, file_name, word_counts))\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "documents = create_document_word_counts(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = DictVectorizer(dtype=np.int_, sparse=False)\n",
    "mydocuments = [{'foo': 1, 'bar': 2}, \n",
    "               {'foo': 3, 'baz': 1, 'foobar': 2, 'bar': 3}]\n",
    "X = vectorizer.fit_transform(mydocuments)\n",
    "\n",
    "print(X)\n",
    "vectorizer.feature_names_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Term frequency - inverse document frequency\n",
    "\n",
    "TF-IDF is a statistical measure that evaluates how relevant a word is to a document in a collection of documents.\n",
    "\n",
    "* TF: Term Frequency, that measures how frequently a term occurs in a document. Since every document is different in length, it is possible that a term would appear much more times in long documents than shorter ones. Thus, the term frequency is often divided by the document length\n",
    "    * $tf(t, d) = \\text{count}(t, d)$\n",
    "    * $tf(t, d) = 1$ if $t$ occurs in $d$ and 0 otherwise;\n",
    "    * $tf(t, d) = \\text{count}(t, d) / (\\text{number of words in d})$\n",
    "    * $tf(t, d) = \\log (1 + \\text{count}(t, d)$)\n",
    "\n",
    "\n",
    "* IDF: Inverse Document Frequency measures how important a term is. While computing TF, all terms are considered equally important. However it is known that certain terms may appear a lot of times but have little importance (e.g. stop words).\n",
    "$$\n",
    "    idf(t, d) = \\frac{|D|}{1 + |d\\in D:\\ t\\in d|}\n",
    "$$    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def create_document_term_matrix(documents):\n",
    "    vectorizer = DictVectorizer(dtype=np.int_, sparse=True)\n",
    "    count_matrix = vectorizer.fit_transform(map(lambda x: x[2], documents))\n",
    "    terms = vectorizer.get_feature_names()\n",
    "    transformer = TfidfTransformer(norm=\"l2\", sublinear_tf=True)\n",
    "    term_matrix = transformer.fit_transform(count_matrix)\n",
    "    document_titles = list(map(lambda x: f'{x[0]}/{x[1]}', documents))\n",
    "    return term_matrix, document_titles, terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "term_matrix, labels, words = create_document_term_matrix(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Similarity of documents\n",
    "\n",
    "\n",
    "* cosine similarity: $\\left < v, w\\right > = ||v||\\cdot ||w||\\cdot\\cos\\phi $\n",
    "\n",
    "The attribute vectors $v$ and $w$ are usually the term frequency vectors of the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "similarity_matrix = pd.DataFrame((term_matrix * term_matrix.T).A, \n",
    "                                 columns=labels, index=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def find_top_k_similar_documents(similarity_matrix, document_name, k):\n",
    "    row = similarity_matrix.loc[document_name, similarity_matrix.columns != document_name]\n",
    "    return row.sort_values(ascending=False)[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "doc_name = 'entertainment/385.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "doc = read_document(f'{base_dir}/{doc_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "similar_documents = find_top_k_similar_documents(similarity_matrix, doc_name, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "similar_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "for fname in similar_documents.index:\n",
    "    doc = read_document(f'{base_dir}{fname}')\n",
    "    print(doc)\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
