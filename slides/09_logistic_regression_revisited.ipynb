{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Logistic regression revisited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Logistic regression for binary classification\n",
    "\n",
    "$h_w(x) \\approx P(y=1 \\vert w; x)$, the probability that $y = 1$ given $x$, parametrized by $w$.\n",
    "\n",
    "$$\n",
    "h(x) = \\sigma(b + w_1\\cdot x_1 + w_2\\cdot x_2 + \\ldots + w_n\\cdot x_n) = \\sigma(w^T\\cdot x + b),\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\sigma(x) = \\frac{1}{1 + e^{-x}}.\n",
    "$$\n",
    "\n",
    "If $h_w(x) = p$, then for the odds\n",
    "$$\n",
    "\\frac{p}{1-p} = \\text{e}^{w^T\\cdot x + b},\n",
    "$$\n",
    "and the log-odds (logit) is\n",
    "$$\n",
    "\\log\\frac{p}{1-p} = w^T\\cdot x + b\n",
    "$$\n",
    "\n",
    "The two classes are separated by a hyperplane: \n",
    "$$\n",
    "y = 1 \\iff w^T\\cdot x + b >= 0.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The cost function is derived from the ML function:\n",
    "\n",
    "$$\n",
    "L(w, b) = \\prod_{x\\colon y=1}h_w(x)\\cdot\\prod_{x\\colon y=0}(1 - h_w(x)) \\rightarrow \\text{max!},\n",
    "$$\n",
    "that is, the negative loglikelihood function should be minimized:\n",
    "$$\n",
    "J(w, b) = \\frac{1}{m}\\sum_{i=1}^m\\left(-y^{(i)}\\cdot\\log h_w(x^{(i)}) - (1 - y^{(i)})\\cdot\\log (1 - h_w(x^{(i)}))\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn.metrics as mcs\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"./data/log_reg_1.txt\") as f:\n",
    "    X = []\n",
    "    y = []\n",
    "    for line in f:\n",
    "        x0, x1, label = line.split(',')\n",
    "        X.append((float(x0), float(x1)))\n",
    "        y.append(int(label))\n",
    "        \n",
    "X = np.array(X)\n",
    "y = np.expand_dims(np.array(y), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def initialize_params(X):\n",
    "    _, nr_features = X.shape\n",
    "    w0 = np.zeros((nr_features, 1), dtype=np.float_)\n",
    "    b = 0.0\n",
    "    return w0, b\n",
    "\n",
    "\n",
    "def activation(Z):\n",
    "    return 1 / (1 + np.exp(-Z))\n",
    "\n",
    "\n",
    "def predict(X, w, b):\n",
    "    A = activation(np.matmul(X, w) + b)\n",
    "    return np.round(A)\n",
    "\n",
    "\n",
    "def calc_gradient(X, y, w, b):\n",
    "    m = len(X)\n",
    "    A = activation(np.matmul(X, w) + b)\n",
    "    cost = (-1 / m) * np.sum(np.multiply(y, np.log(A)) + np.multiply(1 - y, np.log(1 - A)))\n",
    "    \n",
    "    dZ = A - y\n",
    "    dw = (1 / m) * np.matmul(X.T, dZ)\n",
    "    db = (1 / m) * np.sum(dZ)\n",
    "    return cost, dw, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def optimize(X, y, alpha, nr_iterations=10000):\n",
    "    w, b = initialize_params(X)\n",
    "    costs = []\n",
    "    for _ in range(nr_iterations):\n",
    "        cost, dw, db = calc_gradient(X, y, w, b)\n",
    "        costs.append(cost)\n",
    "        w = w - alpha * dw\n",
    "        b = b - alpha * db\n",
    "    return costs, w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "m = np.mean(X, axis=0)\n",
    "s = np.std(X, axis=0, ddof=1)\n",
    "\n",
    "\n",
    "X = (X - m) / s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "alpha = 0.01\n",
    "costs, w, b = optimize(X, y, alpha, nr_iterations=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(16, 8))\n",
    "plt.plot(costs)\n",
    "plt.ylim(0, 0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "predictions = predict(X, w, b)\n",
    "\n",
    "\n",
    "print(mcs.accuracy_score(predictions, y))\n",
    "print(mcs.roc_auc_score(y, predictions))\n",
    "\n",
    "\n",
    "mcs.confusion_matrix(y, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "### Logistic regression in Tensorflow (2.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def optimize(X, y, alpha, nr_epochs):\n",
    "    m, n = X.shape\n",
    "    w = tf.Variable(tf.zeros((n, 1), dtype=np.float64)) # convert input to Tensor\n",
    "    b = tf.Variable(0.0, dtype=np.float64)\n",
    "    \n",
    "    optimizer = tf.optimizers.SGD(learning_rate=alpha)\n",
    "    losses = []\n",
    "    for _ in range(nr_epochs):\n",
    "        y_hat = tf.sigmoid(tf.add(tf.matmul(X, w), b))\n",
    "        loss = tf.reduce_mean(tf.losses.binary_crossentropy(y, y_hat))\n",
    "        dZ = tf.subtract(y_hat, y)\n",
    "        dw = (1 / m) * tf.matmul(tf.transpose(X), dZ)\n",
    "        db = (1 / m) * tf.reduce_sum(dZ)\n",
    "        optimizer.apply_gradients(zip([dw, db], [w, b]))  # w and b are updated under the hood\n",
    "        losses.append(loss)\n",
    "    return losses, w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X_train = tf.Variable(X, dtype=np.float64)\n",
    "Y_train = tf.Variable(y, dtype=np.float64)\n",
    "\n",
    "costs, W, b = optimize(X_train, Y_train, 0.01, 10000)\n",
    "\n",
    "\n",
    "predictions = tf.round(tf.sigmoid(tf.add(tf.matmul(X_train, W), b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "costs = [cost.numpy() for cost in costs]\n",
    "\n",
    "figure = plt.figure(figsize=(16, 8))\n",
    "plt.plot(costs)\n",
    "plt.ylim(0, 0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mcs.accuracy_score(predictions, y))\n",
    "print(mcs.roc_auc_score(y, predictions))\n",
    "\n",
    "\n",
    "mcs.confusion_matrix(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def optimize(X, y, alpha, nr_epochs):\n",
    "    m, n = X.shape\n",
    "    w = tf.Variable(tf.zeros((n, 1), dtype=np.float64)) # convert input to Tensor\n",
    "    b = tf.Variable(0.0, dtype=np.float64)\n",
    "\n",
    "    optimizer = tf.optimizers.SGD(learning_rate=alpha)\n",
    "    losses = []\n",
    "    for _ in range(nr_epochs):\n",
    "        with tf.GradientTape() as g:  # use gradient tape to avoid explicit differentiation\n",
    "            y_hat = tf.sigmoid(tf.add(tf.matmul(X, w), b))\n",
    "            loss = tf.reduce_mean(tf.losses.binary_crossentropy(y, y_hat))\n",
    "            gradients = g.gradient(loss, [w, b])  # here is where dw and db are calculated\n",
    "            optimizer.apply_gradients(zip(gradients, [w, b]))  # w and b are updated under the hood\n",
    "            losses.append(loss)\n",
    "    return losses, w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X_train = tf.Variable(X, dtype=np.float64)\n",
    "Y_train = tf.Variable(y, dtype=np.int_)\n",
    "\n",
    "costs, W, b = optimize(X_train, Y_train, 0.01, 10000)\n",
    "\n",
    "\n",
    "predictions = tf.round(tf.nn.sigmoid(tf.add(tf.matmul(X_train, W), b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "costs = [cost.numpy() for cost in costs]\n",
    "\n",
    "figure = plt.figure(figsize=(16, 8))\n",
    "plt.plot(costs)\n",
    "plt.ylim(0, 0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(mcs.accuracy_score(predictions, y))\n",
    "print(mcs.roc_auc_score(y, predictions))\n",
    "\n",
    "\n",
    "mcs.confusion_matrix(y, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Logistic regression in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](images/log_reg_nn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(units=1, activation='sigmoid', input_shape=(2,))\n",
    "])\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit(X, y, verbose=0, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(16, 8))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.ylim(0, 0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "predictions = np.round(model.predict(X))\n",
    "\n",
    "\n",
    "print(mcs.accuracy_score(predictions, y))\n",
    "print(mcs.roc_auc_score(y, predictions))\n",
    "\n",
    "\n",
    "mcs.confusion_matrix(y, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Adding hidden layers for triangle example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"./data/log_reg_3.txt\") as f:\n",
    "    X = []\n",
    "    y = []\n",
    "    for line in f:\n",
    "        x0, x1, label = line.split(',')\n",
    "        X.append((float(x0), float(x1)))\n",
    "        y.append(int(float(label)))\n",
    "\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.expand_dims(np.array(y), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](images/simple_two_layer_nn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(2,)),\n",
    "    keras.layers.Dense(units=3, activation='sigmoid'),  # try different activation, different units\n",
    "    keras.layers.Dense(units=1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit(X, y, verbose=0, epochs=200)  # try less/more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "predictions = np.round(model.predict(X))\n",
    "\n",
    "\n",
    "print(mcs.accuracy_score(predictions, y))\n",
    "print(mcs.roc_auc_score(y, predictions))\n",
    "\n",
    "\n",
    "mcs.confusion_matrix(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "h = 0.01\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "meshpoints = np.c_[xx.ravel(), yy.ravel()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "Z = model.predict(meshpoints)\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "plt.contourf(xx, yy, Z, alpha=0.1)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Activation function\n",
    "\n",
    "* no activation in hidden layers (does it something useful?)\n",
    "* sigmoid activation (dominant approach before 2014), still OK for the last layer for binary classification\n",
    "* $tanh$ activation (dominant approach between 2015 and 2016)\n",
    "* $\\text{relu}(x) = \\max\\{x, 0\\}$\n",
    "* leaky relu\n",
    "* softmax for multiclass classification"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
